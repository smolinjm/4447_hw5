{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>Jeff Smolinski<br>\n",
    "10/10/2020<br>\n",
    "Homework 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scrapping for Data Scientist job in CO(Total points 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we'll do web scrapping for **Data Scientist job in CO**\n",
    "\n",
    "\n",
    "Here is the link to the search query\n",
    "\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=CO\n",
    "\n",
    "As you can see at the bottom of the page there are link to series of pages related to this search.\n",
    "If you click on second page, search url changes to\n",
    "\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=CO<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=CO&start=10<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=CO&start=20<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=CO&start=30<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=CO&start=40<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=CO&start=50<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=CO&start=60<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=CO&start=70<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=CO&start=80<br>\n",
    "\n",
    "If you click on 3rd then url changes to\n",
    "\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=CO&start=20\n",
    "\n",
    "Hence to go to more pages we can format search string(**change start=??** part) for **requests.get in a loop**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl https://www.indeed.com/robot.txt\n",
    "# FILE NOT FOUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import urllib\n",
    "#import urllib3\n",
    "#http = urllib3.PoolManager()\n",
    "#r = http.request('GET', 'http://indeed.com/robots.txt')\n",
    "#r.status\n",
    "\n",
    "import urllib.robotparser\n",
    "\n",
    "\n",
    "rp = urllib.robotparser.RobotFileParser()\n",
    "rp.set_url('https://www.indeed.com/robot.txt')\n",
    "rp.read()\n",
    "rp.can_fetch('*','https://www.indeed.com/jobs?q=data+scientist&l=CO')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bsoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "pages = []\n",
    "url = 'https://www.indeed.com/jobs?q=data+scientist&l=CO'\n",
    "url2 = 'https://www.indeed.com/jobs?q=data+scientist&l=CO&start='\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = bsoup(response.text, \"html.parser\")\n",
    "pages.append(soup.find(id='resultsCol'))\n",
    "print(0)\n",
    "\n",
    "for i in range(1,9):\n",
    "    \n",
    "    response = requests.get(url2+str(i*10))\n",
    "    #print(response)\n",
    "    soup = bsoup(response.text, \"html.parser\")\n",
    "    #html = open(url2+str(i*10)).read()\n",
    "    #soup = bsoup(html)\n",
    "    pages.append(soup.find(id='resultsCol'))\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 (5 =  4(non indicator columns) + 1(indicator columns) points) Please complete the following task\n",
    "\n",
    "- Scrape 10 pages (**last page(10 th) url will be https://www.indeed.com/jobs?q=data+scientist&l=CO&start=90**)and build a pandas DataFrame containing following information\n",
    "    + **job title, name of the company, location, summary of job description**\n",
    "    + **Indicator columns(with value True/False) about keywords Python, SQL, AWS, RESTFUL, Machine learning, Deep Learning, Text Mining, NLP, SAS, Tableau, Sagemaker, TensorFlow, Spark**\n",
    "\n",
    "Note:\n",
    "- Make sure that you do a case insensitive search for keywords when filing(True/False) in the indicator columns\n",
    "- You need to go to the webpage of detail job posting for keywords search. Main job posting only contains summary of the job description.  Build detail job posting webpage url  from web scrapping main search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING... 0  len\n",
      "Page:  1\n",
      "Page:  2\n",
      "Page:  3\n",
      "Page:  4\n",
      "Page:  5\n",
      "Page:  6\n",
      "Page:  7\n",
      "Page:  8\n",
      "Page:  9\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.DataFrame()\n",
    "print('RUNNING...', len(df_all),' len')\n",
    "\n",
    "count = 0\n",
    "for page_soup in pages:\n",
    "    df = pd.DataFrame()\n",
    "    #job_titles_obj = page_soup.find_all('a',{'class':'jobtitle'})\n",
    "    job_titles = []\n",
    "    company_names = []\n",
    "    locations = []\n",
    "    summaries = []\n",
    "    descriptions = []\n",
    "    #for job in page_soup.find_all('h2',{'class':'title'}):jobsearch-SerpJobCard\n",
    "    \n",
    "    for job in page_soup.find_all('div',{'class':'jobsearch-SerpJobCard'}):\n",
    "        title = job.find('a',{'class':'jobtitle'})\n",
    "        job_titles.append(title.get('title'))\n",
    "        comp_name = job.find('span',{'class':'company'})\n",
    "        company_names.append(comp_name.text.strip())\n",
    "        loca = job.find('div',{'class':'location'})\n",
    "        if loca == None:\n",
    "            loca = job.find('span',{'class':'location'})\n",
    "        locations.append(loca.text.strip())\n",
    "        \n",
    "        summary_obj = job.find('div',{'class':'summary'})\n",
    "        summaries.append(summary_obj)\n",
    "        \n",
    "        url_des = title.get('href')\n",
    "        result = url_des.find('indeed.com')\n",
    "        if result == -1:\n",
    "            url_des = 'https://www.indeed.com'+url_des\n",
    "        #print(url_des)\n",
    "        response = requests.get(url_des)\n",
    "        soup = bsoup(response.text, \"html.parser\")\n",
    "        temp = soup.find(id='jobDescriptionText')\n",
    "        descriptions.append(temp.text.strip())\n",
    "        \n",
    "    count += 1\n",
    "    print('Page: ',count)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #print(job_titles)\n",
    "    df['job_title'] = job_titles\n",
    "    #print(company_names)\n",
    "    df['company_name'] = company_names\n",
    "    #print(locations)\n",
    "    df['location'] = locations\n",
    "    df['summary'] = summaries\n",
    "    \n",
    "    df['description'] = descriptions\n",
    "    # ----\n",
    "    '''\n",
    "    #company_name_obj = page_soup.find_all('a',{'data-tn-element':'companyName'})\n",
    "    company_names = []\n",
    "    for name in page_soup.find_all('span',{'class':'company'}):\n",
    "        company_names.append(name.text.strip())\n",
    "    \n",
    "    print(company_names)\n",
    "    df['company_name'] = company_names\n",
    "    '''\n",
    "    # ----\n",
    "    '''\n",
    "    #location_obj = page_soup.find_all('span',{'class':'location'})\n",
    "    locations = []\n",
    "    for loca in page_soup.find_all('span',{'class':'location'}):\n",
    "        locations.append(loca.text.strip())\n",
    "    \n",
    "    print(locations)\n",
    "    df['location'] = locations\n",
    "    '''\n",
    "    # -----\n",
    "    '''\n",
    "    #sum_divs = page_soup.find_all()\n",
    "    sum_lis = []\n",
    "    for sum_div in page_soup.find_all('div',{'class':'summary'}):\n",
    "        sum_lis.append(sum_div.find('li').contents[0])\n",
    "    \n",
    "    summary = '\\n'.join(sum_lis)\n",
    "    df['summary'] = summary\n",
    "    '''\n",
    "    #df\n",
    "    #print(df)\n",
    "    \n",
    "    if len(df_all) == 0:\n",
    "        df_all = pd.DataFrame(df)\n",
    "        #print(df_all)\n",
    "    else:\n",
    "        #pd.merge(df_all,df, left_on='none', how='left')\n",
    "        df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "    #df_all\n",
    "    \n",
    "    \n",
    "#df_all.head(3)\n",
    "print('done.')\n",
    "#print(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Data Scientist - Finance Domain</td>\n",
       "      <td>IHS Markit</td>\n",
       "      <td>Boulder, CO 80301</td>\n",
       "      <td>[\\n, [\\n, [You have 5+ years of related work e...</td>\n",
       "      <td>Data Scientist – Financial Industry\\nAre you r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>DATA SCIENTIST MANAGER</td>\n",
       "      <td>JBS USA Food Company</td>\n",
       "      <td>Greeley, CO</td>\n",
       "      <td>[\\n, [\\n, [Solid technical hands-on skills in ...</td>\n",
       "      <td>JBS USA is a leading global provider of divers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Machine Learning (ML) Developer</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Broomfield, CO</td>\n",
       "      <td>[\\n, [\\n, [ Experience with regression method...</td>\n",
       "      <td>Role: Machine learning (ML) developer\\n\\nLocat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Data Scientist/Researcher (up to 25% profit sh...</td>\n",
       "      <td>CACI</td>\n",
       "      <td>Aurora, CO 80010 (Delmar Parkway area)</td>\n",
       "      <td>[\\n, [\\n, [In depth knowledge and practical ex...</td>\n",
       "      <td>Job Description\\nJob Description\\nBITS, a CACI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Data Engineer With Sippd</td>\n",
       "      <td>MORI Associates, Inc.</td>\n",
       "      <td>United States</td>\n",
       "      <td>[\\n, [\\n, [Work closely and interactively with...</td>\n",
       "      <td>Data Engineer Job Description\\nTake your caree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Ascent Services Group</td>\n",
       "      <td>Denver, CO 80246 (Southeastern Denver area)</td>\n",
       "      <td>[\\n, [\\n, [There is typically several back and...</td>\n",
       "      <td>Req #: 20-07349\\nTitle: Junior Data Scientist\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>xentity corporation</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>[\\n, [\\n, [1 year of consulting experience – h...</td>\n",
       "      <td>Our Government and Large Commercial high-profi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Havenly</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>[\\n, [\\n, [While a part of the job will be tra...</td>\n",
       "      <td>Havenly, Inc. is a funded and fast growing con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Artificial Intelligence, Consultant - Applied ...</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>[\\n, [\\n, [Perform , &lt;b&gt;data&lt;/b&gt;,  studies and...</td>\n",
       "      <td>Strategy &amp; Analytics-Analytics and Cognitive\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Senior Quality Data Analyst</td>\n",
       "      <td>SCL Health Corporate</td>\n",
       "      <td>Broomfield, CO 80038</td>\n",
       "      <td>[\\n, [\\n, [Minimum of five (5) years of experi...</td>\n",
       "      <td>You.\\nYou bring your body, mind, heart and spi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_title           company_name  \\\n",
       "64                     Data Scientist - Finance Domain             IHS Markit   \n",
       "111                             DATA SCIENTIST MANAGER   JBS USA Food Company   \n",
       "25                     Machine Learning (ML) Developer                    TCS   \n",
       "92   Data Scientist/Researcher (up to 25% profit sh...                   CACI   \n",
       "123                           Data Engineer With Sippd  MORI Associates, Inc.   \n",
       "117                              Junior Data Scientist  Ascent Services Group   \n",
       "28                                Data Science Analyst    xentity corporation   \n",
       "53                           Machine Learning Engineer                Havenly   \n",
       "90   Artificial Intelligence, Consultant - Applied ...               Deloitte   \n",
       "66                         Senior Quality Data Analyst   SCL Health Corporate   \n",
       "\n",
       "                                        location  \\\n",
       "64                             Boulder, CO 80301   \n",
       "111                                  Greeley, CO   \n",
       "25                                Broomfield, CO   \n",
       "92        Aurora, CO 80010 (Delmar Parkway area)   \n",
       "123                                United States   \n",
       "117  Denver, CO 80246 (Southeastern Denver area)   \n",
       "28                                    Denver, CO   \n",
       "53                                    Denver, CO   \n",
       "90                                    Denver, CO   \n",
       "66                          Broomfield, CO 80038   \n",
       "\n",
       "                                               summary  \\\n",
       "64   [\\n, [\\n, [You have 5+ years of related work e...   \n",
       "111  [\\n, [\\n, [Solid technical hands-on skills in ...   \n",
       "25   [\\n, [\\n, [ Experience with regression method...   \n",
       "92   [\\n, [\\n, [In depth knowledge and practical ex...   \n",
       "123  [\\n, [\\n, [Work closely and interactively with...   \n",
       "117  [\\n, [\\n, [There is typically several back and...   \n",
       "28   [\\n, [\\n, [1 year of consulting experience – h...   \n",
       "53   [\\n, [\\n, [While a part of the job will be tra...   \n",
       "90   [\\n, [\\n, [Perform , <b>data</b>,  studies and...   \n",
       "66   [\\n, [\\n, [Minimum of five (5) years of experi...   \n",
       "\n",
       "                                           description  \n",
       "64   Data Scientist – Financial Industry\\nAre you r...  \n",
       "111  JBS USA is a leading global provider of divers...  \n",
       "25   Role: Machine learning (ML) developer\\n\\nLocat...  \n",
       "92   Job Description\\nJob Description\\nBITS, a CACI...  \n",
       "123  Data Engineer Job Description\\nTake your caree...  \n",
       "117  Req #: 20-07349\\nTitle: Junior Data Scientist\\...  \n",
       "28   Our Government and Large Commercial high-profi...  \n",
       "53   Havenly, Inc. is a funded and fast growing con...  \n",
       "90   Strategy & Analytics-Analytics and Cognitive\\n...  \n",
       "66   You.\\nYou bring your body, mind, heart and spi...  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.reset_index(drop=True) # fail\n",
    "df_all.reindex(axis=\"columns\")\n",
    "\n",
    "df_all.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_all.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Natural Language Processing Engineer</td>\n",
       "      <td>Pearson</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>[\\n, [\\n, [Strong in using Jupyter notebooks f...</td>\n",
       "      <td>Description\\nWe are the world’s learning compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>STRIVE HEALTH</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>[\\n, [\\n, [Working knowledge of analyzing medi...</td>\n",
       "      <td>Strive Overview:\\nFounded in 2018, Strive Heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Hotel Engine</td>\n",
       "      <td>Denver, CO 80246 (Southeastern Denver area)</td>\n",
       "      <td>[\\n, [\\n, [Partner with , &lt;b&gt;data&lt;/b&gt;,  engine...</td>\n",
       "      <td>Hotel Engine (https://www.hotelengine.com) is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               job_title   company_name  \\\n",
       "78  Natural Language Processing Engineer        Pearson   \n",
       "32                      Sr. Data Analyst  STRIVE HEALTH   \n",
       "26                 Senior Data Scientist   Hotel Engine   \n",
       "\n",
       "                                       location  \\\n",
       "78                                  Boulder, CO   \n",
       "32                                   Denver, CO   \n",
       "26  Denver, CO 80246 (Southeastern Denver area)   \n",
       "\n",
       "                                              summary  \\\n",
       "78  [\\n, [\\n, [Strong in using Jupyter notebooks f...   \n",
       "32  [\\n, [\\n, [Working knowledge of analyzing medi...   \n",
       "26  [\\n, [\\n, [Partner with , <b>data</b>,  engine...   \n",
       "\n",
       "                                          description  \n",
       "78  Description\\nWe are the world’s learning compa...  \n",
       "32  Strive Overview:\\nFounded in 2018, Strive Heal...  \n",
       "26  Hotel Engine (https://www.hotelengine.com) is ...  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'SQL', 'AWS', 'RESTFUL', 'Machine learning', 'Deep Learning', 'Text Mining', 'NLP', 'SAS', 'Tableau', 'Sagemaker', 'TensorFlow', 'Spark']\n"
     ]
    }
   ],
   "source": [
    "keywords = 'Python, SQL, AWS, RESTFUL, Machine learning, Deep Learning, Text Mining, NLP, SAS, Tableau, Sagemaker, TensorFlow, Spark'\n",
    "\n",
    "keys = keywords.split(', ')\n",
    "#keys = [x.lower() for x in keys]\n",
    "print(keys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Req #: 20-07349\\nTitle: Junior Data Scientist\\...\n",
       "1      Req #: 20-07348\\nTitle Data Scientist III\\nLoc...\n",
       "2      GRS # 162897\\n\\n\\nRole: Data Scientist\\n\\n\\nLo...\n",
       "3      Our client is a Data Analytics, a market leade...\n",
       "4      The coolest jobs on this planet… or any other…...\n",
       "                             ...                        \n",
       "127    Embedded Machine Learning Research Engineer\\nB...\n",
       "128    Artificial Intelligence, Senior Consultant – A...\n",
       "129    Artificial Intelligence, Consultant - Applied ...\n",
       "130    BS in Computer Science or related technical fi...\n",
       "131    Strategy & Analytics-Analytics and Cognitive\\n...\n",
       "Name: description, Length: 132, dtype: object"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python\n",
      "SQL\n",
      "AWS\n",
      "RESTFUL\n",
      "Machine_learning\n",
      "Deep_Learning\n",
      "Text_Mining\n",
      "NLP\n",
      "SAS\n",
      "Tableau\n",
      "Sagemaker\n",
      "TensorFlow\n",
      "Spark\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for k in keys:\n",
    "    strs = df_2.description\n",
    "    x = []\n",
    "    #for i in strs:\n",
    "        #x.append(i.str.contains(k, na=False, case=False))\n",
    "    x = strs.str.contains(str(k), na=False, case=False)\n",
    "    kk = k.replace(' ','_')\n",
    "    print(kk)\n",
    "    df_2[kk] = x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>Python</th>\n",
       "      <th>SQL</th>\n",
       "      <th>AWS</th>\n",
       "      <th>RESTFUL</th>\n",
       "      <th>Machine_learning</th>\n",
       "      <th>Deep_Learning</th>\n",
       "      <th>Text_Mining</th>\n",
       "      <th>NLP</th>\n",
       "      <th>SAS</th>\n",
       "      <th>Tableau</th>\n",
       "      <th>Sagemaker</th>\n",
       "      <th>TensorFlow</th>\n",
       "      <th>Spark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>PART TIME DATA SCIENCE INTERN-CAREER DEVELOPMENT</td>\n",
       "      <td>JBS USA Food Company</td>\n",
       "      <td>Greeley, CO</td>\n",
       "      <td>[\\n, [\\n, [Technical hands-on skills in machin...</td>\n",
       "      <td>JBS USA is a leading global provider of divers...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Dataiku</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>[\\n, [\\n, [Our ideal candidate is comfortable ...</td>\n",
       "      <td>Dataiku allows enterprises to create value wit...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Director , Corporate Security-Artificial Intel...</td>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>Englewood, CO 80110</td>\n",
       "      <td>[\\n, [\\n, [Management and Security Architectur...</td>\n",
       "      <td>Cognizant requires an AI&amp;A expert with a stron...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_title  \\\n",
       "76    PART TIME DATA SCIENCE INTERN-CAREER DEVELOPMENT   \n",
       "11                                      Data Scientist   \n",
       "113  Director , Corporate Security-Artificial Intel...   \n",
       "\n",
       "                       company_name             location  \\\n",
       "76             JBS USA Food Company          Greeley, CO   \n",
       "11                          Dataiku           Denver, CO   \n",
       "113  Cognizant Technology Solutions  Englewood, CO 80110   \n",
       "\n",
       "                                               summary  \\\n",
       "76   [\\n, [\\n, [Technical hands-on skills in machin...   \n",
       "11   [\\n, [\\n, [Our ideal candidate is comfortable ...   \n",
       "113  [\\n, [\\n, [Management and Security Architectur...   \n",
       "\n",
       "                                           description  Python    SQL    AWS  \\\n",
       "76   JBS USA is a leading global provider of divers...    True   True   True   \n",
       "11   Dataiku allows enterprises to create value wit...    True   True   True   \n",
       "113  Cognizant requires an AI&A expert with a stron...   False  False  False   \n",
       "\n",
       "     RESTFUL  Machine_learning  Deep_Learning  Text_Mining    NLP    SAS  \\\n",
       "76     False              True           True        False  False  False   \n",
       "11     False              True          False        False  False  False   \n",
       "113    False             False          False        False  False  False   \n",
       "\n",
       "     Tableau  Sagemaker  TensorFlow  Spark  \n",
       "76     False      False        True  False  \n",
       "11     False      False       False   True  \n",
       "113    False      False       False  False  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     84\n",
       "False    48\n",
       "Name: Machine_learning, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_2['Machine_learning'][60:90]\n",
    "df_2['Machine_learning'].value_counts()\n",
    "#df_2.loc[df_2['Machine_learning'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 (1 point) Save your DataFrame to pickle file name *indeed_job_co.pkl*. \n",
    "   Load this pkl file in dataFrame and use this dataFrame for answering following questions.\n",
    "\n",
    "   <font color='red'>upload the pickle file(indeed_job_co.pkl) along with solution notebook to the canvas</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write code here\n",
    "import pickle\n",
    "import sys\n",
    "sys.setrecursionlimit(100000)\n",
    "df_all.to_pickle(\"./indeed_job_co.pkl\") #potentially_malicious.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded2 = pd.read_pickle(\"./indeed_job_co.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Applied Machine Learning Engineer Intern</td>\n",
       "      <td>Ricoh</td>\n",
       "      <td>Boulder, CO 80301</td>\n",
       "      <td>[\\n, [\\n, [You will be looking at big , &lt;b&gt;dat...</td>\n",
       "      <td>Internship Program Overview\\nOur interns will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>GIS Data Analyst/Scientist, Task 6.9.2.4</td>\n",
       "      <td>Indrasoft</td>\n",
       "      <td>Aurora, CO</td>\n",
       "      <td>[\\n, [\\n, [Knowledge of , &lt;b&gt;data&lt;/b&gt;,  scienc...</td>\n",
       "      <td>Job Details\\nDescription\\nJob Title: GIS Data ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   job_title company_name           location  \\\n",
       "87  Applied Machine Learning Engineer Intern        Ricoh  Boulder, CO 80301   \n",
       "77  GIS Data Analyst/Scientist, Task 6.9.2.4    Indrasoft         Aurora, CO   \n",
       "\n",
       "                                              summary  \\\n",
       "87  [\\n, [\\n, [You will be looking at big , <b>dat...   \n",
       "77  [\\n, [\\n, [Knowledge of , <b>data</b>,  scienc...   \n",
       "\n",
       "                                          description  \n",
       "87  Internship Program Overview\\nOur interns will ...  \n",
       "77  Job Details\\nDescription\\nJob Title: GIS Data ...  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loaded2.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"6\" color='red'> Use pandas functionality to answer question 2</font>\n",
    "# Q3 a (1 point) Which city has maximum job posting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denver, final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Denver, CO                                           30\n",
       "Boulder, CO                                          11\n",
       "Denver, CO 80202 (Central Business District area)     7\n",
       "Colorado                                              6\n",
       "Greeley, CO                                           5\n",
       "Denver, CO 80246 (Southeastern Denver area)           5\n",
       "Colorado Springs, CO                                  5\n",
       "Boulder, CO 80301                                     5\n",
       "Englewood, CO                                         4\n",
       "Aurora, CO                                            4\n",
       "Broomfield, CO (Interlocken area)                     2\n",
       "Englewood, CO 80110                                   2\n",
       "Boulder, CO 80305 (Central Boulder area)              2\n",
       "Denver, CO 80202 (Lodo area)                          2\n",
       "Lafayette, CO                                         2\n",
       "Aurora, CO 80011 (Norfolk Glen area)                  2\n",
       "Fort Collins, CO                                      2\n",
       "Littleton, CO 80120                                   2\n",
       "Denver, CO 80237 (Hampden South area)                 2\n",
       "Broomfield, CO                                        2\n",
       "Denver, CO 80237 (Southeastern Denver area)           2\n",
       "Boulder, CO 80309 (Colorado University area)          2\n",
       "United States                                         2\n",
       "Golden, CO 80401                                      2\n",
       "Greenwood Village, CO 80111                           2\n",
       "Englewood, CO 80112                                   2\n",
       "Evergreen, CO 80437                                   1\n",
       "Denver, CO 80238                                      1\n",
       "Broomfield, CO 80038                                  1\n",
       "Colorado Springs, CO 80920 (Briargate area)           1\n",
       "Broomfield, CO 80021                                  1\n",
       "Centennial, CO 80122                                  1\n",
       "Louisville, CO                                        1\n",
       "Greenwood Village, CO 80121                           1\n",
       "Denver, CO 80225                                      1\n",
       "Denver, CO 80014                                      1\n",
       "Longmont, CO                                          1\n",
       "Centennial, CO 80112                                  1\n",
       "Denver, CO 80201                                      1\n",
       "Broomfield, CO 80021 (Interlocken area)               1\n",
       "Arvada, CO                                            1\n",
       "Aurora, CO 80010 (Delmar Parkway area)                1\n",
       "Colorado Springs, CO 80914 (Powers area)              1\n",
       "Boulder, CO 80302 (Whittier area)                     1\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2['location'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 b (1.5 point) - Top 3 most demanding skills(like Python, AWS, SQL ...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Float64Index([nan, nan], dtype='float64')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-975f2e2c99ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#dx.set_index([0], inplace=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#print(dx.loc['True'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(df_2.loc[dx[i] == True].sum())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/envs/env_unix/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/envs/env_unix/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0;31m# handle the dup indexing case GH#4246\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/envs/env_unix/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/envs/env_unix/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/envs/env_unix/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1039\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/envs/env_unix/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/envs/env_unix/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Float64Index([nan, nan], dtype='float64')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "\n",
    "for i in df_2.columns[5:]:\n",
    "    print(i)\n",
    "    print(type(df_2[i].value_counts()))\n",
    "    dx = df_2[i].value_counts()\n",
    "    #dx.set_index([0], inplace=True)\n",
    "    print(dx)\n",
    "    true_count = df_2[i].sum()\n",
    "    print(true_count)\n",
    "    #print(dx.loc['True'])\n",
    "    #print(df_2.loc[dx[i] == True].sum())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 c(.5 point) What other questions you would like to ask  based on indeed data?\n",
    "\n",
    "This is free response questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your anser in this cell. Double click this cell to edit this cell*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
